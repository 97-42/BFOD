<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}
	
	h1 {
		font-size:32px;
		font-weight:300;
	}
	
	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		        15px 15px 0 0px #fff, /* The fourth layer */
		        15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		        20px 20px 0 0px #fff, /* The fifth layer */
		        20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		        25px 25px 0 0px #fff, /* The fifth layer */
		        25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
	    top: 50%;
	    transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
  <head>
		<title>Making Convolutional Networks Shift-Invariant Again</title>
		<meta property="og:image" content="https://richzhang.github.io/antialiased-cnns/resources/teaser_fb4.jpg"/>
		<meta property="og:title" content="Making ConvNets Shift-Invariant Again. ICML 2019." />

		<!-- Global site tag (gtag.js) - Google Analytics -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=UA-75863369-6"></script>
		<script>
		  window.dataLayer = window.dataLayer || [];
		  function gtag(){dataLayer.push(arguments);}
		  gtag('js', new Date());

		  gtag('config', 'UA-75863369-6');
		</script>
  </head>

  <body>
    <br>
          <center>
          	<span style="font-size:36px">Making Convolutional Networks Shift-Invariant Again</span>
	  		  <table align=center width=600px>
	  			  <tr>
	  	              <td align=center width=100px>
	  					<center>
	  						<span style="font-size:28px"><a href="https://richzhang.github.io/">Richard Zhang</a></span><br>
	  						<span style="font-size:22px">Adobe Research</span>
		  		  		</center>
		  		  	  </td>
		  		  </tr>
	  			  <tr>
		  		  </tr>
			  </table>
	  		  <table align=center width=350px>
	  			  <tr>
	  	              <td align=center width=175px>
	  					<center>
	  						<span style="font-size:24px"><a href='https://arxiv.org/abs/1904.11486'>[Paper]</a></span>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=175px>
	  					<center>
	  						<span style="font-size:24px"><a href='https://github.com/richzhang/antialiased-cnns'>[GitHub]</a></span> <br> <span style="font-size:18px"> (under construction)</span>
		  		  		</center>
		  		  	  </td>
		  		  	 </tr>
	  			  <tr>
			  </table>
          </center>

          <center>
  		  <table align=center width=900px>
  			  <tr>
  	              <td width=300px>
  					<center>
  	                	<a href='./resources/gifs/00810.gif'><img class="round" style="width:300px" src="./resources/gifs/00810.gif"/></a>
	  				</center>
  	              </td>
    	          <td width=300px>
  					<center>
  	                	<a href='./resources/gifs/12911.gif'><img class="round" style="width:300px" src="./resources/gifs/12911.gif"/></a>
	  				</center>
  	              </td>
                  <td width=300px>
  					<center>
  	                	<a href='./resources/gifs/47458.gif'><img class="round" style="width:300px" src="./resources/gifs/47458.gif"/></a>
	  				</center>
  	              </td>
                </tr>
<!--   			  <tr>
  	              <td width=300px>
  					<center>
  	                	<a href='./resources/gifs/28476.gif'><img class="round" style="width:300px" src="./resources/gifs/28476.gif"/></a>
	  				</center>
  	              </td>
    	          <td width=300px>
  					<center>
  	                	<a href='./resources/gifs/28347.gif'><img class="round" style="width:300px" src="./resources/gifs/28347.gif"/></a>
	  				</center>
  	              </td>
                  <td width=300px>
  					<center>
  	                	<a href='./resources/gifs/35969.gif'><img class="round" style="width:300px" src="./resources/gifs/35969.gif"/></a>
	  				</center>
  	              </td>
                </tr> -->
  		  </table>
  		  <table align=center width=850px>
	  		  <tr>
	  		  	<td>
	  		  		<!-- <center> -->
					Small shifts -- even by a single pixel -- can drastically change the output of a deep network (bars on left). We identify the cause: aliasing during downsampling. We anti-alias modern deep networks with classic signal processing, stabilizing output classifications (bars on right). We even observe accuracy increases (see plot below).
					<!-- </center> -->
	  		    </td>
	  		  </tr>
	  		</table>
  		</center>

          <hr>

<!--   		  <br>
  		  <table align=center width=800px>
  			  <tr>
  	              <td width=400px>
  					<center>
  	                	<a href="./resources/fig1d.jpeg"><img class="" src = "./resources/fig1d.jpeg" height="400px"></img></href></a><br>
					</center>
  	              </td>
                </tr>
  		  </table>
		  <hr> -->

  		  <table align=center width=850px>
	  		  <center><h1>Abstract</h1></center>
	  		  <tr>
	  		  	<td>
					Modern convolutional networks are not shift-invariant, as small input shifts or translations can cause drastic changes in the output. Commonly used downsampling methods, such as max-pooling, strided-convolution, and average-pooling, ignore the sampling theorem. The well-known signal processing fix is anti-aliasing by low-pass filtering before downsampling. However, simply inserting this module into deep networks leads to performance degradation; as a result, it is seldomly used today. We show that when integrated correctly, it is compatible with existing architectural components, such as max-pooling. The technique is general and can be incorporated across layer types and applications, such as image classification and conditional image generation. In addition to increased shift-invariance, we also observe, surprisingly, that anti-aliasing boosts accuracy in ImageNet classification, across several commonly-used architectures. This indicates that anti-aliasing serves as effective regularization. Our results demonstrate that this classical signal processing technique has been undeservingly overlooked in modern deep networks.
	  		    </td>
	  		  </tr>
			</table>
  		  <br>
		  <hr>



  		  <table align=center width=700px>
	  		  <center><h1>Method overview</h1></center>
  			  <tr>
  	              <td align=center width=700px>
  					<center>
						  <td><a href='https://github.com/richzhang/antialiased-cnns'><img class="round" style="width:800px" src="./resources/fig1e.jpg"/></a></td>
	  		  		</center>
			  </tr>
		  </table>
		  <br>
  		  <table align=center width=850px>
		  	<center>
		  		<tr>
		  			<td>
		  	We anti-alias modern networks with classic signal processing, making them more shift-invariant. Predominant downsampling methods ignore the Nyquist sampling theorem. We make the following replacements: <br>MaxPool&rarr;MaxBlurPool (pictured above), StridedConv&rarr;ConvBlurPool, and AvgPool&rarr;BlurPool.
		  			</td>
		  		</tr>
		  </center>
		  </table>
		  <hr>

	  <!-- NETWORK ARCHITECTURE, TRY THE MODEL -->
 		<center><h1>Code (coming soon)</h1></center>

  		  <table align=center width=420px>
		  	<center>
		  		<tr>
		  			<td>
		  				<b>ImageNet Classification (shift-invariance vs accuracy)</b>
		  			</td>
		  		</tr>
		  </center>
		  </table>
  		  <table align=center width=400px>
  			  <tr>
  	              <td align=center width=400px>
  					<center>
						  <td><a href='https://github.com/richzhang/antialiased-cnns'><img class="round" style="width:400px" src="./resources/imagenet_agg_all.jpg"/></a></td>
						  <!-- <td><img class="round" style="width:400px" src="./resources/imagenet_agg_all.jpg"/></td> -->
	  		  		</center>
			  </tr>
		  </table>
  		  <table align=center width=850px>
		  	<center>
		  		<tr>
		  			<td>
		  	As designed, adding low-pass filtering increases <b>shift-invariance (y-axis)</b>. Surprisingly, we also observe modest increases in <b>accuracy (x-axis)</b>, across architectures. We will release anti-aliased models and training code, along with instructions for making your favorite architecture more shift-invariant.
		  			</td>
		  		</tr>
		  </center>
		  </table>
  		  <table align=center width=800px>
			  <br>
			  <tr><center>
				<span style="font-size:28px">&nbsp;<a href='https://github.com/richzhang/antialiased-cnns'>[GitHub]</a> (under construction)
		  </table>


<!-- <a href="http://www.eecs.berkeley.edu/~rich.zhang/projects/2016_colorization/files/demo_v0/colorization_release_v0.caffemodel">[Model 129MB]</span> -->

      	  <br>
		  <hr>

  		  <!-- <table align=center width=550px> -->
  		  <table align=center width=490px>
	 		<center><h1>Paper and Supplementary Material</h1></center>
  			  <tr>
				  <td><a href="https://arxiv.org/abs/1904.11486"><img class="layered-paper-big" style="height:175px" src="./resources/paper.png"/></a></td>
				  <td><span style="font-size:14pt">R. Zhang.<br>
				  <b>Making Convolutional Networks Shift-Invariant Again.</b><br>
				  To appear in ICML, 2019.<br>
				  (<a href="https://arxiv.org/abs/1904.11486">ArXiv</a> preprint)<br>
				  <span style="font-size:4pt"><a href=""><br></a>
				  </span>
				  </td>
  	              </td>
              </tr>
  		  </table>
		  <br>

		  <table align=center width=600px>
			  <tr>
				  <td><span style="font-size:14pt"><center>
				  	<a href="./resources/bibtex_icml19.txt">[Bibtex]</a>
  	              </center></td>
              </tr>
  		  </table>

		  <hr>
		  <br>
		  	
  		  <table align=center width=900px>
  			  <tr>
  	              <td width=400px>
  					<left>
	  		  <center><h1>Acknowledgements</h1></center>
<!-- 	  		  I thank <a href="https://research.adobe.com/person/eli-shechtman/">Eli Shechtman</a>, 
	  		  <a href="http://www.mgharbi.com/">Michaël Gharbi</a>,
	  		  <a href="http://www.oliverwang.info/">Oliver Wang</a>,
	  		  <a href="http://andrewowens.com/">Andrew Owens</a>, 
	  		  <a href="https://people.eecs.berkeley.edu/~efros/">Alexei A. Efros<a>,
	  		  <a href="https://people.eecs.berkeley.edu/~kanazawa/">Angjoo Kanazawa</a>, and
	  		  <a href="http://web.mit.edu/phillipi/">Phillip Isola<a> for their helpful discussion, comments, and encouragement.
 -->
				I am especially grateful to Eli Shechtman for helpful discussion and guidance. I also thank Michaël Gharbi and Andrew Owens for the beneficial feedback on earlier drafts. I thank labmates and mentors, past and present -- Sylvain Paris, Oliver Wang, Alexei A. Efros, Angjoo Kanazawa, Taesung Park, Phillip Isola -- for their helpful comments and encouragement.

			</left>
		</td>
			 </tr>
		</table>

		<br>

              
</body>
</html>
 
